{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn opencv-python-headless\n\n# Importing required packages\nimport os\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.layers import TextVectorization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding\nfrom tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gradio jinja2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gradio as gr","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:42:58.425152Z","iopub.execute_input":"2023-04-10T07:42:58.425520Z","iopub.status.idle":"2023-04-10T07:43:00.286432Z","shell.execute_reply.started":"2023-04-10T07:42:58.425478Z","shell.execute_reply":"2023-04-10T07:43:00.285082Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Reading the dataset into a pandas dataframe\nfile_path = 'train.csv'\n\ntry:\n    df = pd.read_csv(file_path)\n    X = df['comment_text']\n    y = df[df.columns[2:]].values\n    print(\"\"Dataset loaded successfully.\"\")\nexcept FileNotFoundError:\n    print(f\"\"Dataset not found at '{file_path}'. Please place the 'train.csv' file in the same folder as the notebook.\"\")","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:43:00.288967Z","iopub.execute_input":"2023-04-10T07:43:00.289702Z","iopub.status.idle":"2023-04-10T07:43:02.421851Z","shell.execute_reply.started":"2023-04-10T07:43:00.289643Z","shell.execute_reply":"2023-04-10T07:43:02.420552Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Defining the maximum number of features\nMAX_FEATURES = 200000","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:43:02.423533Z","iopub.execute_input":"2023-04-10T07:43:02.423904Z","iopub.status.idle":"2023-04-10T07:43:02.428727Z","shell.execute_reply.started":"2023-04-10T07:43:02.423859Z","shell.execute_reply":"2023-04-10T07:43:02.427605Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Creating a TextVectorization layer for encoding and adapting the training dataset\nvectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n                               output_sequence_length=max([len(x.split()) for x in X.values]),\n                               output_mode='int')\nvectorizer.adapt(X.values)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:43:02.430167Z","iopub.execute_input":"2023-04-10T07:43:02.430752Z","iopub.status.idle":"2023-04-10T07:43:14.241992Z","shell.execute_reply.started":"2023-04-10T07:43:02.430715Z","shell.execute_reply":"2023-04-10T07:43:14.240742Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Creating a TensorFlow dataset from the vectorized text and labels\ndataset = tf.data.Dataset.from_tensor_slices((vectorizer(X.values), y))\ndataset = dataset.cache()\ndataset = dataset.shuffle(160000)\ndataset = dataset.batch(16)\ndataset = dataset.prefetch(8) # helps with bottlenecks","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:43:14.244578Z","iopub.execute_input":"2023-04-10T07:43:14.245486Z","iopub.status.idle":"2023-04-10T07:43:19.014098Z","shell.execute_reply.started":"2023-04-10T07:43:14.245431Z","shell.execute_reply":"2023-04-10T07:43:19.012807Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Splitting dataset into train, validation, and test sets\ntrain = dataset.take(int(len(dataset)*.7))\nval = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\ntest = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:43:19.016066Z","iopub.execute_input":"2023-04-10T07:43:19.016575Z","iopub.status.idle":"2023-04-10T07:43:19.031905Z","shell.execute_reply.started":"2023-04-10T07:43:19.016533Z","shell.execute_reply":"2023-04-10T07:43:19.030508Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Defining a Bidirectional LSTM model\nmodel = Sequential([\n    Embedding(MAX_FEATURES+1, 32),\n    Bidirectional(LSTM(32, activation='tanh')),\n    Dense(128, activation='relu'),\n    Dense(256, activation='relu'),\n    Dense(128, activation='relu'),\n    Dense(6, activation='sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:43:19.033564Z","iopub.execute_input":"2023-04-10T07:43:19.034271Z","iopub.status.idle":"2023-04-10T07:43:19.825659Z","shell.execute_reply.started":"2023-04-10T07:43:19.034228Z","shell.execute_reply":"2023-04-10T07:43:19.824327Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Compiling the model using Binary Cross Entropy loss function and Adam optimizer\nmodel.compile(loss='BinaryCrossentropy', optimizer='Adam')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:43:19.829340Z","iopub.execute_input":"2023-04-10T07:43:19.829767Z","iopub.status.idle":"2023-04-10T07:43:19.850357Z","shell.execute_reply.started":"2023-04-10T07:43:19.829726Z","shell.execute_reply":"2023-04-10T07:43:19.849157Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Define model file path\nmodel_filepath = '/kaggle/input/toxicityweights/toxicity.h5'","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:43:19.852150Z","iopub.execute_input":"2023-04-10T07:43:19.853064Z","iopub.status.idle":"2023-04-10T07:43:19.858386Z","shell.execute_reply.started":"2023-04-10T07:43:19.853011Z","shell.execute_reply":"2023-04-10T07:43:19.857042Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Check if a pre-trained model exists and load it\nif os.path.exists(model_filepath):\n    print(\"Loading pre-trained model...\")\n    model = tf.keras.models.load_model(model_filepath)\nelse:\n    print(\"Training the model...\")\n    history = model.fit(train, epochs=1, validation_data=val)\n    model.save(model_filepath)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:43:19.859927Z","iopub.execute_input":"2023-04-10T07:43:19.860231Z","iopub.status.idle":"2023-04-10T07:43:22.718619Z","shell.execute_reply.started":"2023-04-10T07:43:19.860201Z","shell.execute_reply":"2023-04-10T07:43:22.717308Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Loading pre-trained model...\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation metrics\npre = Precision()\nre = Recall()\nacc = CategoricalAccuracy()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:43:22.720092Z","iopub.execute_input":"2023-04-10T07:43:22.720442Z","iopub.status.idle":"2023-04-10T07:43:22.737647Z","shell.execute_reply.started":"2023-04-10T07:43:22.720407Z","shell.execute_reply":"2023-04-10T07:43:22.736274Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Calculate Precision, Recall, and Categorical Accuracy scores for the model\nfor batch in test.as_numpy_iterator(): \n    X_true, y_true = batch\n    yhat = model.predict(X_true)\n    y_true = y_true.flatten()\n    yhat = yhat.flatten()\n    pre.update_state(y_true, yhat)\n    re.update_state(y_true, yhat)\n    acc.update_state(y_true, yhat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Precision:{pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:46:43.318463Z","iopub.execute_input":"2023-04-10T07:46:43.318934Z","iopub.status.idle":"2023-04-10T07:46:43.341142Z","shell.execute_reply.started":"2023-04-10T07:46:43.318891Z","shell.execute_reply":"2023-04-10T07:46:43.339620Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Precision:0.8457186222076416, Recall:0.6319053173065186, Accuracy:0.47943830490112305\n","output_type":"stream"}]},{"cell_type":"code","source":"# Defining a 'score_comment' function to predict toxicity labels for an input comment,\n# vectorize the comment, get predictions, and format the results as a string.\nfrom io import BytesIO\nimport base64\n\ndef score_comment(comment, category=None, custom=None):\n    vectorized_comment = vectorizer([comment])\n    \n    if category and custom:\n        # Add custom phrase or word to the input data\n        sequence_length = vectorized_comment.shape[1]\n        X_custom = np.zeros((1, sequence_length), dtype=np.int64)\n        custom_text = '{} {}'.format(category, custom)\n        vectorized_custom = vectorizer([custom_text])\n        X_custom[:, :len(vectorized_custom[0])] = vectorized_custom\n        X = np.vstack([vectorized_comment, X_custom])\n    else:\n        X = vectorized_comment\n    \n    results = model.predict(X)[-1]\n\n    # Create a bar chart of category probabilities\n    fig, ax = plt.subplots()\n    y_pos = np.arange(len(df.columns[2:]))\n    ax.barh(y_pos, results, align='center')\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels(df.columns[2:])\n    ax.invert_yaxis()  # labels read top-to-bottom\n    ax.set_xlabel('Probability')\n    ax.set_title('Category Probabilities')\n\n    # Save the plot to a buffer\n    buf = BytesIO()\n    plt.savefig(buf, format='png')\n    buf.seek(0)\n\n    # Convert the buffer to a base64 encoded string\n    encoded_img = base64.b64encode(buf.getvalue()).decode('utf-8')\n    plt.close(fig)\n\n    # Convert base64 image to numpy array\n    nparr = np.frombuffer(base64.b64decode(encoded_img), np.uint8)\n    img_np = cv2.imdecode(nparr, cv2.IMREAD_UNCHANGED)\n\n    return img_np","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:46:43.343195Z","iopub.execute_input":"2023-04-10T07:46:43.344280Z","iopub.status.idle":"2023-04-10T07:46:43.358994Z","shell.execute_reply.started":"2023-04-10T07:46:43.344225Z","shell.execute_reply":"2023-04-10T07:46:43.357735Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Creating an interface for the model using Gradio to take user input,\n# display predictions and probability distributions for different categories,\n# and provide a visual output.\ninterface = gr.Interface(fn=score_comment,\n                         inputs=[gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n                                 gr.inputs.CheckboxGroup(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], label='Categories'),\n                                 gr.inputs.Textbox(label='Custom phrase or word', optional=True)],\n                         outputs=gr.outputs.Image(type='pil'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interface.launch(share=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:46:45.062179Z","iopub.execute_input":"2023-04-10T07:46:45.063119Z","iopub.status.idle":"2023-04-10T07:46:58.763339Z","shell.execute_reply.started":"2023-04-10T07:46:45.063081Z","shell.execute_reply":"2023-04-10T07:46:58.762278Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://5b3deadcbea868278d.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://5b3deadcbea868278d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]}]}